{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/izzal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/izzal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tag                patterns\n",
      "0    notfound                        \n",
      "1    notfound                        \n",
      "2    notfound                        \n",
      "3    notfound                        \n",
      "4    notfound                        \n",
      "..        ...                     ...\n",
      "330     tidak               tidak ada\n",
      "331     tidak  ga ada pertanyaan lagi\n",
      "332     tidak                  ga ada\n",
      "333     tidak     ga ada terima kasih\n",
      "334     tidak  tidak ada teri makasih\n",
      "\n",
      "[335 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('../assets/intents.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Ekstrak kolom \"tag\" dan \"patterns\" dari JSON bersarang\n",
    "selected_data = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    tag = intent[\"tag\"]\n",
    "    patterns = intent[\"patterns\"]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        selected_data.append({\"tag\": tag, \"patterns\": pattern})\n",
    "\n",
    "# Buat DataFrame dari data yang diambil\n",
    "df = pd.DataFrame(selected_data)\n",
    "\n",
    "# Tampilkan DataFrame yang dihasilkan\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               []\n",
       "1                               []\n",
       "2                               []\n",
       "3                               []\n",
       "4                               []\n",
       "                  ...             \n",
       "330                   [tidak, ada]\n",
       "331    [ga, ada, pertanyaan, lagi]\n",
       "332                      [ga, ada]\n",
       "333       [ga, ada, terima, kasih]\n",
       "334    [tidak, ada, teri, makasih]\n",
       "Name: patterns, Length: 335, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['patterns'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               []\n",
       "1                               []\n",
       "2                               []\n",
       "3                               []\n",
       "4                               []\n",
       "                  ...             \n",
       "330                   [tidak, ada]\n",
       "331    [ga, ada, pertanyaan, lagi]\n",
       "332                      [ga, ada]\n",
       "333       [ga, ada, terima, kasih]\n",
       "334    [tidak, ada, teri, makasih]\n",
       "Name: patterns, Length: 335, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['patterns'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal/Alphanumeric Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     []\n",
       "1                                                     []\n",
       "2                                                     []\n",
       "3                                                     []\n",
       "4                                                     []\n",
       "                             ...                        \n",
       "330                             [t, i, d, a, k, a, d, a]\n",
       "331    [g, a, a, d, a, p, e, r, t, a, n, y, a, a, n, ...\n",
       "332                                      [g, a, a, d, a]\n",
       "333     [g, a, a, d, a, t, e, r, i, m, a, k, a, s, i, h]\n",
       "334    [t, i, d, a, k, a, d, a, t, e, r, i, m, a, k, ...\n",
       "Name: patterns, Length: 335, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"patterns\"].apply(lambda x: [y for y in x if y.isalnum()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
